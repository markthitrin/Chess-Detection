{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation(image) :\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    _, otsu_thresholded = cv2.threshold(blurred_image, 165, 255, cv2.THRESH_BINARY)\n",
    "    edges_image = cv2.Canny(otsu_thresholded, threshold1=50, threshold2=150)\n",
    "    dilation_kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated_image = cv2.dilate(edges_image, dilation_kernel, iterations=1)\n",
    "    lines = cv2.HoughLinesP(dilated_image, 1, np.pi/180, threshold=200, minLineLength=100, maxLineGap=25)\n",
    "    hough_image = dilated_image\n",
    "    if lines is not None:\n",
    "        for i, line in enumerate(lines):\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(hough_image, (x1, y1), (x2, y2), (255,255,255), 3)\n",
    "\n",
    "    erosion_kernel = np.ones((3, 3), np.uint8)\n",
    "    erosed_image = cv2.erode(hough_image, erosion_kernel, iterations=1)\n",
    "    return erosed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_red_line(image) :\n",
    "    lines = cv2.HoughLines(image, rho=1, theta=np.pi/180, threshold=250)\n",
    "    output_lines = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            output_lines.append([x1,y1,x2,y2])\n",
    "    return output_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_red_lines(image, lines) :\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1,y1,x2,y2 = line\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_oriented_line(image) : \n",
    "    lines = cv2.HoughLines(image, rho=1, theta=np.pi/180, threshold=250)\n",
    "    horizontal_lines = []\n",
    "    vertical_lines = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            if np.pi / 2 - 0.1 <= theta <= np.pi / 2 + 0.1:\n",
    "                horizontal_lines.append((rho, theta))\n",
    "            elif theta <= 0.1 or theta >= np.pi - 0.1:\n",
    "                vertical_lines.append((rho, theta))\n",
    "    return (horizontal_lines, vertical_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oriented_line(image) :\n",
    "    horizontal_lines, vertical_lines = get_raw_oriented_line(image)\n",
    "    output_horizontal_lines = []\n",
    "    output_vertical_ilnes = []\n",
    "    # Draw horizontal lines\n",
    "    for rho, theta in horizontal_lines:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 1000 * (-b))\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "        output_horizontal_lines.append([x1,y1,x2,y2])\n",
    "    # Draw vertical lines\n",
    "    for rho, theta in vertical_lines:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 1000 * (-b))\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "        output_vertical_ilnes.append([x1,y1,x2,y2])\n",
    "    return output_horizontal_lines, output_vertical_ilnes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_oriented_line(image, horizontal_lines, vertical_lines) :\n",
    "    for h_line in horizontal_lines:\n",
    "        x1, y1, x2, y2 = h_line\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    for v_line in vertical_lines:\n",
    "        x1, y1, x2, y2 = v_line\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection_point(image) : \n",
    "    horizontal_lines, vertical_lines = get_raw_oriented_line(image)\n",
    "    intersection_points = []\n",
    "\n",
    "    for rho_h, theta_h in horizontal_lines:\n",
    "        for rho_v, theta_v in vertical_lines:\n",
    "            a_h = np.cos(theta_h)\n",
    "            b_h = np.sin(theta_h)\n",
    "            a_v = np.cos(theta_v)\n",
    "            b_v = np.sin(theta_v)\n",
    "            determinant = a_h * b_v - b_h * a_v\n",
    "            if abs(determinant) > 1e-10: \n",
    "                x = (b_v * rho_h - b_h * rho_v) / determinant\n",
    "                y = (a_h * rho_v - a_v * rho_h) / determinant\n",
    "                intersection_points.append((int(x), int(y)))\n",
    "    return intersection_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_intersection_point(image,intersection_points) :\n",
    "    for x, y in intersection_points:\n",
    "        cv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corner(image, intersection_points) :\n",
    "    red_regions = cv2.cvtColor(put_intersection_point(image * 0, intersection_points), cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(red_regions, cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    dst = cv2.cornerHarris(gray, blockSize=2, ksize=3, k=0.04)\n",
    "    threshold = 0.01 * dst.max()\n",
    "    corners = np.argwhere(dst > threshold)\n",
    "    height, width = gray.shape\n",
    "    image_corners = [\n",
    "        (0, 0),               # Top-left\n",
    "        (0, height - 1),       # Top-right 0, width - 1\n",
    "        (width - 1, 0),      # Bottom-left height - 1, 0\n",
    "        (height - 1, width - 1)  # Bottom-right\n",
    "    ]\n",
    "    refined_corners = []\n",
    "    for corner in image_corners:\n",
    "        distances = np.linalg.norm(corners - np.array(corner), axis=1)\n",
    "        closest_idx = np.argmin(distances)\n",
    "        refined_corners.append([corners[closest_idx][1],corners[closest_idx][0]])\n",
    "    \n",
    "    return refined_corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_crop_image(image, corners) :\n",
    "    corners = np.float32(corners)\n",
    "    src_points = corners\n",
    "    dst_points = np.float32([\n",
    "        [0, 0],\n",
    "        [500, 0],\n",
    "        [0, 500],\n",
    "        [500, 500]\n",
    "    ])\n",
    "    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    output_size = (500, 500) \n",
    "    warped_image = cv2.warpPerspective(image, matrix, output_size)\n",
    "    \n",
    "    return warped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sol2(image) :\n",
    "    transformed_image = apply_transformation(image)\n",
    "    red_lines = get_red_line(transformed_image)\n",
    "    horizontal_lines, vertical_lines = get_oriented_line(transformed_image)\n",
    "    intersection_points = get_intersection_point(transformed_image)\n",
    "    corners = get_corner(image,intersection_points)\n",
    "    croped_image = apply_crop_image(image,corners)\n",
    "    plt.imshow(croped_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chess piece detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER = \"yolov5/\"\n",
    "VIDEO_FOLDER = \"yolov5/test-video/\"\n",
    "OUTPUT_FOLDER = \"\"\n",
    "\n",
    "MODEL_FILE = \"chess-v2.pt\"\n",
    "VIDEO_FILE = \"2_move_student.mp4\"\n",
    "OUTPUT_FILE = \"detectAlgoOutput.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1_, y1_, x2_, y2_ = box2\n",
    "\n",
    "    xi1, yi1 = max(x1, x1_), max(y1, y1_)\n",
    "    xi2, yi2 = min(x2, x2_), min(y2, y2_)\n",
    "    inter_area = max(0, xi2 - xi1 + 1) * max(0, yi2 - yi1 + 1)\n",
    "\n",
    "    box1_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    box2_area = (x2_ - x1_ + 1) * (y2_ - y1_ + 1)\n",
    "\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    return inter_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_custom(detections, iou_threshold=0.6):\n",
    "    filtered_boxes = []\n",
    "    while len(detections) > 0:\n",
    "        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n",
    "        best_box = detections.pop(0) \n",
    "        filtered_boxes.append(best_box)\n",
    "\n",
    "        detections = [\n",
    "            box for box in detections\n",
    "            if calculate_iou(\n",
    "                (best_box['xmin'], best_box['ymin'], best_box['xmax'], best_box['ymax']),\n",
    "                (box['xmin'], box['ymin'], box['xmax'], box['ymax'])\n",
    "            ) < iou_threshold\n",
    "        ]\n",
    "    return filtered_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model() :\n",
    "    # device = torch.device('cuda')\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=MODEL_FOLDER + MODEL_FILE)\n",
    "    model.conf = 0.2\n",
    "    model.iou = 0.9\n",
    "    # model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_predict(frame, model) :\n",
    "    # model.to()\n",
    "    results = model(frame)\n",
    "    detections = results.pandas().xyxy[0]\n",
    "    detections_list = [\n",
    "        {\n",
    "            'xmin': int(row['xmin']),\n",
    "            'ymin': int(row['ymin']),\n",
    "            'xmax': int(row['xmax']),\n",
    "            'ymax': int(row['ymax']),\n",
    "            'confidence': float(row['confidence']),\n",
    "            'name': row['name']\n",
    "        }\n",
    "        for _, row in detections.iterrows()\n",
    "    ]\n",
    "    filtered_detections = non_max_suppression_custom(detections_list, iou_threshold=0.6)\n",
    "    return filtered_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()\n",
    "\n",
    "video_path = VIDEO_FOLDER + VIDEO_FILE\n",
    "output_path = OUTPUT_FOLDER + OUTPUT_FILE\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_path, fourcc, 1, (width, height))\n",
    "\n",
    "frame_count = 0\n",
    "processed_frame = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_count % fps == 0:\n",
    "        filtered_detections = get_frame_predict(frame, model)\n",
    "\n",
    "        print(f\"Filtered detections for frame {frame_count}:\")\n",
    "        for detection in filtered_detections:\n",
    "            print(detection)\n",
    "\n",
    "        for det in filtered_detections:\n",
    "            xmin, ymin, xmax, ymax = det['xmin'], det['ymin'], det['xmax'], det['ymax']\n",
    "            label = f\"{det['name']} {det['confidence']:.2f}\"\n",
    "            color = (0, 255, 0) if det['name'] == \"chessboard\" else (0, 0, 255)  # Green for chessboard, Red for pieces\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "            cv2.putText(frame, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('YOLOv5 Chess Detection', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Video with detections (1 FPS) saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
