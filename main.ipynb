{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "from scipy.spatial.distance import cdist\n",
    "from sympy import Point, Polygon, Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation(image) :\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    _, otsu_thresholded = cv2.threshold(blurred_image, 165, 255, cv2.THRESH_BINARY)\n",
    "    edges_image = cv2.Canny(otsu_thresholded, threshold1=50, threshold2=150)\n",
    "    dilation_kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated_image = cv2.dilate(edges_image, dilation_kernel, iterations=1)\n",
    "    lines = cv2.HoughLinesP(dilated_image, 1, np.pi/180, threshold=200, minLineLength=100, maxLineGap=25)\n",
    "    hough_image = dilated_image\n",
    "    if lines is not None:\n",
    "        for i, line in enumerate(lines):\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(hough_image, (x1, y1), (x2, y2), (255,255,255), 3)\n",
    "\n",
    "    erosion_kernel = np.ones((3, 3), np.uint8)\n",
    "    erosed_image = cv2.erode(hough_image, erosion_kernel, iterations=1)\n",
    "    return erosed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_red_line(image) :\n",
    "    lines = cv2.HoughLines(image, rho=1, theta=np.pi/180, threshold=250)\n",
    "    output_lines = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            output_lines.append([x1,y1,x2,y2])\n",
    "    return output_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_red_lines(image, lines) :\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1,y1,x2,y2 = line\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_oriented_line(image) : \n",
    "    lines = cv2.HoughLines(image, rho=1, theta=np.pi/180, threshold=250)\n",
    "    horizontal_lines = []\n",
    "    vertical_lines = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            if np.pi / 2 - 0.1 <= theta <= np.pi / 2 + 0.1:\n",
    "                horizontal_lines.append((rho, theta))\n",
    "            elif theta <= 0.1 or theta >= np.pi - 0.1:\n",
    "                vertical_lines.append((rho, theta))\n",
    "    return (horizontal_lines, vertical_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oriented_line(image) :\n",
    "    horizontal_lines, vertical_lines = get_raw_oriented_line(image)\n",
    "    output_horizontal_lines = []\n",
    "    output_vertical_ilnes = []\n",
    "    # Draw horizontal lines\n",
    "    for rho, theta in horizontal_lines:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 1000 * (-b))\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "        output_horizontal_lines.append([x1,y1,x2,y2])\n",
    "    # Draw vertical lines\n",
    "    for rho, theta in vertical_lines:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 1000 * (-b))\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "        output_vertical_ilnes.append([x1,y1,x2,y2])\n",
    "    return output_horizontal_lines, output_vertical_ilnes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_oriented_line(image, horizontal_lines, vertical_lines) :\n",
    "    for h_line in horizontal_lines:\n",
    "        x1, y1, x2, y2 = h_line\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    for v_line in vertical_lines:\n",
    "        x1, y1, x2, y2 = v_line\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection_point(image) : \n",
    "    horizontal_lines, vertical_lines = get_raw_oriented_line(image)\n",
    "    intersection_points = []\n",
    "\n",
    "    for rho_h, theta_h in horizontal_lines:\n",
    "        for rho_v, theta_v in vertical_lines:\n",
    "            a_h = np.cos(theta_h)\n",
    "            b_h = np.sin(theta_h)\n",
    "            a_v = np.cos(theta_v)\n",
    "            b_v = np.sin(theta_v)\n",
    "            determinant = a_h * b_v - b_h * a_v\n",
    "            if abs(determinant) > 1e-10: \n",
    "                x = (b_v * rho_h - b_h * rho_v) / determinant\n",
    "                y = (a_h * rho_v - a_v * rho_h) / determinant\n",
    "                intersection_points.append((int(x), int(y)))\n",
    "    return intersection_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_intersection_point(image,intersection_points) :\n",
    "    for x, y in intersection_points:\n",
    "        cv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corner(image, intersection_points) :\n",
    "    red_regions = cv2.cvtColor(put_intersection_point(image * 0, intersection_points), cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(red_regions, cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    dst = cv2.cornerHarris(gray, blockSize=2, ksize=3, k=0.04)\n",
    "    threshold = 0.01 * dst.max()\n",
    "    corners = np.argwhere(dst > threshold)\n",
    "    height, width = gray.shape\n",
    "    image_corners = [\n",
    "        (0, 0),               # Top-left\n",
    "        (0, height - 1),       # Top-right 0, width - 1\n",
    "        (width - 1, 0),      # Bottom-left height - 1, 0\n",
    "        (height - 1, width - 1)  # Bottom-right\n",
    "    ]\n",
    "    refined_corners = []\n",
    "    for corner in image_corners:\n",
    "        distances = np.linalg.norm(corners - np.array(corner), axis=1)\n",
    "        closest_idx = np.argmin(distances)\n",
    "        refined_corners.append([corners[closest_idx][1],corners[closest_idx][0]])\n",
    "    \n",
    "    return refined_corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_crop_image(image, corners) :\n",
    "    corners = np.float32(corners)\n",
    "    src_points = corners\n",
    "    dst_points = np.float32([\n",
    "        [0, 0],\n",
    "        [500, 0],\n",
    "        [0, 500],\n",
    "        [500, 500]\n",
    "    ])\n",
    "    matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    output_size = (500, 500) \n",
    "    warped_image = cv2.warpPerspective(image, matrix, output_size)\n",
    "    \n",
    "    return warped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sol2(image) :\n",
    "    transformed_image = apply_transformation(image)\n",
    "    red_lines = get_red_line(transformed_image)\n",
    "    horizontal_lines, vertical_lines = get_oriented_line(transformed_image)\n",
    "    intersection_points = get_intersection_point(transformed_image)\n",
    "    corners = get_corner(image,intersection_points)\n",
    "    croped_image = apply_crop_image(image,corners)\n",
    "    plt.imshow(put_oriented_line(image,horizontal_lines,vertical_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_intersection(_line1, _line2):\n",
    "    line1 = (_line1[0:2],_line1[2:4])\n",
    "    line2 = (_line2[0:2],_line2[2:4])\n",
    "    xdiff = (line1[0][0] - line1[1][0], line2[0][0] - line2[1][0])\n",
    "    ydiff = (line1[0][1] - line1[1][1], line2[0][1] - line2[1][1])\n",
    "\n",
    "    def det(a, b):\n",
    "        return a[0] * b[1] - a[1] * b[0]\n",
    "\n",
    "    div = det(xdiff, ydiff)\n",
    "    if div == 0:\n",
    "       return -1, -1\n",
    "\n",
    "    d = (det(*line1), det(*line2))\n",
    "    x = det(d, xdiff) / div\n",
    "    y = det(d, ydiff) / div\n",
    "    return x, y\n",
    "\n",
    "def filter_separate_lines(lines):\n",
    "    separate_lines = []\n",
    "    for i, line1 in enumerate(lines):\n",
    "        is_separate_from_all = True\n",
    "        for j, line2 in enumerate(separate_lines):\n",
    "            x,y = line_intersection(line1,line2)\n",
    "            if x >= 0 and x <= 600 and y >= 0 and y <= 600:\n",
    "                is_separate_from_all = False\n",
    "                break\n",
    "        if is_separate_from_all:\n",
    "            separate_lines.append(line1)\n",
    "    return separate_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersect_board_line(lines,corners) :\n",
    "    output_lines = []\n",
    "    for line in lines :\n",
    "        board_poly = Polygon(corners[0], corners[1], corners[3], corners[2])\n",
    "        if board_poly.intersection(Line(Point(line[0],line[1]), Point(line[2], line[3]))) :\n",
    "            output_lines.append(line)\n",
    "    return output_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shrink_corners(corners, x) :\n",
    "    corners[0][0] += x\n",
    "    corners[0][1] += x\n",
    "    corners[1][0] -= x\n",
    "    corners[1][1] += x\n",
    "    corners[2][0] -= x\n",
    "    corners[2][1] -= x\n",
    "    corners[3][0] += x\n",
    "    corners[3][1] -= x\n",
    "    return corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_cordinate(image, corners = None, horizontal_lines = None, vertical_lines = None) :\n",
    "    if corners == None :\n",
    "        transformed_image = apply_transformation(image)\n",
    "        intersection_points = get_intersection_point(transformed_image)\n",
    "        corners = get_corner(image,intersection_points)\n",
    "    shrink_corners = get_shrink_corners([corners[0],corners[1],corners[3],corners[2]], 0)\n",
    "    board_mask = cv2.fillPoly(image * 0,[np.array(shrink_corners)],(255,255,255))\n",
    "    mask_image = cv2.bitwise_and(image,board_mask)\n",
    "    if(horizontal_lines == None or vertical_lines == None) :\n",
    "        transformed_image = apply_transformation(image)\n",
    "        horizontal_lines, vertical_lines = get_oriented_line(transformed_image)\n",
    "    horizontal_lines_separate = filter_separate_lines(horizontal_lines)\n",
    "    vertical_lines_separate = filter_separate_lines(vertical_lines)\n",
    "    horizontal_lines_intersect = get_intersect_board_line(horizontal_lines_separate, shrink_corners)\n",
    "    vertical_lines_intersect = get_intersect_board_line(vertical_lines_separate, shrink_corners)\n",
    "\n",
    "    plt.imshow(mask_image)\n",
    "    plt.savefig(\"output.jpg\")\n",
    "\n",
    "    return horizontal_lines_intersect, vertical_lines_intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[-1004, 250, 995, 285],\n",
       "  [-1004, 248, 995, 283],\n",
       "  [-1002, 141, 997, 176],\n",
       "  [-1001, 91, 997, 126],\n",
       "  [-1005, 304, 994, 339],\n",
       "  [-1000, 441, 999, 442],\n",
       "  [-1003, 194, 996, 229],\n",
       "  [-1006, 361, 993, 396]],\n",
       " [[208, 1003, 243, -995],\n",
       "  [75, 1003, 144, -995],\n",
       "  [281, 1000, 281, -1000],\n",
       "  [316, -1005, 351, 994],\n",
       "  [351, -1012, 421, 985],\n",
       "  [409, -1014, 479, 983],\n",
       "  [148, 1002, 183, -996]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"image.jpg\")\n",
    "get_cell_cordinate(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chess piece detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER = \"yolov5/\"\n",
    "VIDEO_FOLDER = \"yolov5/test-video/\"\n",
    "OUTPUT_FOLDER = \"\"\n",
    "\n",
    "MODEL_FILE = \"chess-v2.pt\"\n",
    "VIDEO_FILE = \"2_move_student.mp4\"\n",
    "OUTPUT_FILE = \"detectAlgoOutput.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_piece(board, data, horizontal_lines_intersect, vertical_lines_intersect) :\n",
    "    def is_point_left(p, l):\n",
    "        x, y = p\n",
    "        x1, y1, x2, y2 = l\n",
    "        return (x2 - x1) * (y - y1) - (y2 - y1) * (x - x1) > 0\n",
    "    def is_point_right(p, l):\n",
    "        x, y = p\n",
    "        x1, y1, x2, y2 = l\n",
    "        return (x2 - x1) * (y - y1) - (y2 - y1) * (x - x1) < 0\n",
    "    def is_point_above(p, l):\n",
    "        x, y = p\n",
    "        x1, y1, x2, y2 = l\n",
    "        if x1 == x2:\n",
    "            return y > max(y1, y2)\n",
    "        y_on_line = y1 + (y2 - y1) * (x - x1) / (x2 - x1)\n",
    "        return y > y_on_line\n",
    "    def is_point_below(p, l):\n",
    "        x, y = p\n",
    "        x1, y1, x2, y2 = l\n",
    "        if x1 == x2:\n",
    "            return y < min(y1, y2) \n",
    "        y_on_line = y1 + (y2 - y1) * (x - x1) / (x2 - x1)\n",
    "        return y < y_on_line\n",
    "    h_index = 0\n",
    "    v_index = 0\n",
    "    center = ((data[\"xmax\"] + data[\"xmin\"]) / 2, (data[\"ymax\"] * 0.2 + data[\"ymin\"] * 0.8))\n",
    "    for l in vertical_lines_intersect :\n",
    "        print(\"l\")\n",
    "        if is_point_right(center, l) :\n",
    "            h_index = h_index + 1\n",
    "    for l in horizontal_lines_intersect :\n",
    "        print(\"k\")\n",
    "        if is_point_above(center, l) :\n",
    "            v_index = v_index + 1\n",
    "    print(v_index,h_index)\n",
    "    board[v_index][h_index] = data[\"name\"]\n",
    "    \n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1_, y1_, x2_, y2_ = box2\n",
    "\n",
    "    xi1, yi1 = max(x1, x1_), max(y1, y1_)\n",
    "    xi2, yi2 = min(x2, x2_), min(y2, y2_)\n",
    "    inter_area = max(0, xi2 - xi1 + 1) * max(0, yi2 - yi1 + 1)\n",
    "\n",
    "    box1_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    box2_area = (x2_ - x1_ + 1) * (y2_ - y1_ + 1)\n",
    "\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    return inter_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_custom(detections, iou_threshold=0.6):\n",
    "    filtered_boxes = []\n",
    "    while len(detections) > 0:\n",
    "        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n",
    "        best_box = detections.pop(0) \n",
    "        filtered_boxes.append(best_box)\n",
    "\n",
    "        detections = [\n",
    "            box for box in detections\n",
    "            if calculate_iou(\n",
    "                (best_box['xmin'], best_box['ymin'], best_box['xmax'], best_box['ymax']),\n",
    "                (box['xmin'], box['ymin'], box['xmax'], box['ymax'])\n",
    "            ) < iou_threshold\n",
    "        ]\n",
    "    return filtered_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model() :\n",
    "    # device = torch.device('cuda')\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=MODEL_FOLDER + MODEL_FILE)\n",
    "    model.conf = 0.2\n",
    "    model.iou = 0.9\n",
    "    # model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_predict(frame, model) :\n",
    "    # model.to()\n",
    "    results = model(frame)\n",
    "    detections = results.pandas().xyxy[0]\n",
    "    detections_list = [\n",
    "        {\n",
    "            'xmin': int(row['xmin']),\n",
    "            'ymin': int(row['ymin']),\n",
    "            'xmax': int(row['xmax']),\n",
    "            'ymax': int(row['ymax']),\n",
    "            'confidence': float(row['confidence']),\n",
    "            'name': row['name']\n",
    "        }\n",
    "        for _, row in detections.iterrows()\n",
    "    ]\n",
    "    filtered_detections = non_max_suppression_custom(detections_list, iou_threshold=0.6)\n",
    "    return filtered_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\asus/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-12-9 Python-3.12.4 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7042489 parameters, 0 gradients, 15.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080 1920\n",
      "hhhh :  43 43\n",
      "Filtered detections for frame 0:\n",
      "{'xmin': 126, 'ymin': 488, 'xmax': 195, 'ymax': 604, 'confidence': 0.9014763832092285, 'name': 'w-rook'}\n",
      "{'xmin': 567, 'ymin': 938, 'xmax': 625, 'ymax': 1022, 'confidence': 0.8820989727973938, 'name': 'w-pawn'}\n",
      "{'xmin': 126, 'ymin': 613, 'xmax': 190, 'ymax': 711, 'confidence': 0.8594576716423035, 'name': 'w-pawn'}\n",
      "{'xmin': 330, 'ymin': 535, 'xmax': 414, 'ymax': 716, 'confidence': 0.8538987636566162, 'name': 'w-queen'}\n",
      "{'xmin': 558, 'ymin': 462, 'xmax': 638, 'ymax': 624, 'confidence': 0.8536826372146606, 'name': 'w-rook'}\n",
      "{'xmin': 445, 'ymin': 831, 'xmax': 502, 'ymax': 924, 'confidence': 0.8485519289970398, 'name': 'w-pawn'}\n",
      "{'xmin': 893, 'ymin': 499, 'xmax': 962, 'ymax': 614, 'confidence': 0.8458411693572998, 'name': 'w-rook'}\n",
      "{'xmin': 227, 'ymin': 618, 'xmax': 287, 'ymax': 713, 'confidence': 0.8316799998283386, 'name': 'w-pawn'}\n",
      "{'xmin': 459, 'ymin': 940, 'xmax': 519, 'ymax': 1030, 'confidence': 0.8059220314025879, 'name': 'b-pawn'}\n",
      "{'xmin': 693, 'ymin': 620, 'xmax': 756, 'ymax': 718, 'confidence': 0.7715937495231628, 'name': 'w-pawn'}\n",
      "{'xmin': 344, 'ymin': 492, 'xmax': 407, 'ymax': 612, 'confidence': 0.7594640254974365, 'name': 'w-bishop'}\n",
      "{'xmin': 894, 'ymin': 907, 'xmax': 973, 'ymax': 1038, 'confidence': 0.7453349232673645, 'name': 'b-knight'}\n",
      "{'xmin': 778, 'ymin': 830, 'xmax': 840, 'ymax': 917, 'confidence': 0.7109683156013489, 'name': 'w-rook'}\n",
      "{'xmin': 875, 'ymin': 623, 'xmax': 946, 'ymax': 717, 'confidence': 0.7076073884963989, 'name': 'w-rook'}\n",
      "{'xmin': 209, 'ymin': 1257, 'xmax': 286, 'ymax': 1363, 'confidence': 0.6420539617538452, 'name': 'b-knight'}\n",
      "{'xmin': 71, 'ymin': 1253, 'xmax': 158, 'ymax': 1358, 'confidence': 0.6385625004768372, 'name': 'w-rook'}\n",
      "{'xmin': 910, 'ymin': 1167, 'xmax': 984, 'ymax': 1255, 'confidence': 0.6353409886360168, 'name': 'b-rook'}\n",
      "{'xmin': 920, 'ymin': 1258, 'xmax': 1018, 'ymax': 1357, 'confidence': 0.5079925656318665, 'name': 'b-rook'}\n",
      "{'xmin': 662, 'ymin': 717, 'xmax': 741, 'ymax': 829, 'confidence': 0.4910935163497925, 'name': 'w-rook'}\n",
      "{'xmin': 564, 'ymin': 1253, 'xmax': 634, 'ymax': 1358, 'confidence': 0.4891161322593689, 'name': 'b-bishop'}\n",
      "{'xmin': 548, 'ymin': 1142, 'xmax': 622, 'ymax': 1244, 'confidence': 0.43271633982658386, 'name': 'b-queen'}\n",
      "{'xmin': 450, 'ymin': 1257, 'xmax': 524, 'ymax': 1369, 'confidence': 0.4156050384044647, 'name': 'b-knight'}\n",
      "{'xmin': 562, 'ymin': 1046, 'xmax': 627, 'ymax': 1133, 'confidence': 0.3925030529499054, 'name': 'b-knight'}\n",
      "{'xmin': 795, 'ymin': 1161, 'xmax': 872, 'ymax': 1250, 'confidence': 0.32434961199760437, 'name': 'b-rook'}\n",
      "{'xmin': 330, 'ymin': 1272, 'xmax': 409, 'ymax': 1362, 'confidence': 0.31007808446884155, 'name': 'b-bishop'}\n",
      "{'xmin': 203, 'ymin': 1164, 'xmax': 268, 'ymax': 1251, 'confidence': 0.28064772486686707, 'name': 'b-rook'}\n",
      "[['-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-'], ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-']]\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "l\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "k\n",
      "0 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(frame, label, (xmin, ymin \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.5\u001b[39m, color, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m#----\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m     board_test \u001b[38;5;241m=\u001b[39m \u001b[43mput_piece\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mh_cell_line\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv_cell_line\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m out\u001b[38;5;241m.\u001b[39mwrite(frame)\n\u001b[0;32m     52\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYOLOv5 Chess Detection\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n",
      "Cell \u001b[1;32mIn[66], line 36\u001b[0m, in \u001b[0;36mput_piece\u001b[1;34m(board, data, horizontal_lines_intersect, vertical_lines_intersect)\u001b[0m\n\u001b[0;32m     34\u001b[0m         v_index \u001b[38;5;241m=\u001b[39m v_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(v_index,h_index)\n\u001b[1;32m---> 36\u001b[0m \u001b[43mboard\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mh_index\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m board\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "\n",
    "video_path = VIDEO_FOLDER + VIDEO_FILE\n",
    "output_path = OUTPUT_FOLDER + OUTPUT_FILE\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(width,height)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_path, fourcc, 1, (width, height))\n",
    "\n",
    "frame_count = 0\n",
    "processed_frame = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # ----\n",
    "    # h_cell_line,v_cell_line = get_cell_cordinate(frame)\n",
    "    plt.imshow(frame)\n",
    "    plt.savefig(\"output.jpg\")\n",
    "    print(\"hhhh : \",len(h_cell_line),len(v_cell_line))\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_count % fps == 0:\n",
    "        filtered_detections = get_frame_predict(frame, model)\n",
    "\n",
    "        print(f\"Filtered detections for frame {frame_count}:\")\n",
    "        for detection in filtered_detections:\n",
    "            print(detection)\n",
    "\n",
    "        #----\n",
    "        board_test = [[\"-\"] * 10] * 10\n",
    "        print(board_test)\n",
    "        for det in filtered_detections:\n",
    "            xmin, ymin, xmax, ymax = det['xmin'], det['ymin'], det['xmax'], det['ymax']\n",
    "            label = f\"{det['name']} {det['confidence']:.2f}\"\n",
    "            color = (0, 255, 0) if det['name'] == \"chessboard\" else (0, 0, 255)  # Green for chessboard, Red for pieces\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "            cv2.putText(frame, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            #----\n",
    "            board_test = put_piece(board_test,det,h_cell_line,v_cell_line)\n",
    "\n",
    "        \n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('YOLOv5 Chess Detection', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Video with detections (1 FPS) saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
